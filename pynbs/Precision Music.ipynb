{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddfd0148",
   "metadata": {},
   "source": [
    "## The Problem: \n",
    "Live music is dynamic. \n",
    "Musicians watch and listen to the audience. \n",
    "Their movements, their screams, chants, satisfaction or disappointment. \n",
    "Recorded music is sanitized. \n",
    "It's nice, but can become uninteresting. \n",
    "Making matters worse, when our affective states and emotions change, we leave our music behind. \n",
    "\n",
    "For example, if you start an exercise routine listening to one kind of music, your heart rate increases. 5-10 minutes later your heart rate has double from 65bpm to 130bpm. You outran your music1 \n",
    "\n",
    "### Solution: \n",
    "Precision Music created **hybrid generative music.** \n",
    "That is, we edited music in real time with ultra-low latency and loss. That way, you can listen to your familiar music and it would follow you on your journey. Windows of music were edited and served every second. \n",
    "\n",
    "### Challenge 1: \n",
    "#### Latency: \n",
    "Minimizing latency was a major challenge. At the time, I was a beginner programmer. After 2-3 months of coding, the code finally ran. There was major latency. I became depressed: \"what if there the computation costs are too high?\" No. There was no other option but to move forward. I had to do this. I completed the first low-latency version on July 4th, 2021. (I remember the date because the whole country set off fireworks to celebrate my achievement.) This struggle was solved using multi processing. Later on, I further reduced latency to the affective goal by using a sliding window. \n",
    "\n",
    "### Challenge 2: \n",
    "#### Hardware: \n",
    "Extracting, transforming, and loading (ETL) data over a wireless connection from a consumer wearable device was... complicated. Not only was this done in real time, but it needed to weed out anomalies. For example, a heart rate of 60 might sometimes read as 120. ETL for wearables data was entire standalone project. (There is now a startup that makes connecting wearables dev friendly, wish that was around when I was coding.) \n",
    "\n",
    "### Challenge 3:\n",
    "#### Audio Transforms: \n",
    "**MAJOR CHALLENGE.** This was the key component. I'll get into more detail later. \n",
    "Involved: \n",
    "* Digital Signal Processing\n",
    "* Fourier transforms\n",
    "* Librosa\n",
    "* PyRubberBand\n",
    "* PyAudio\n",
    "* Time stretching\n",
    "* Pitch shifting\n",
    "\n",
    "### Challenge 4: \n",
    "#### User Testing, visualization: \n",
    "I ran some user tests. We created a live graph of heart rates and music tempo. \n",
    "\n",
    "### Challenge 5: \n",
    "#### Can music control physiologies? \n",
    "I designed an open loop control system. Selected instead of reinforcement learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e74201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
